# Agent æ¶æ„è®¾è®¡æ¨¡å¼

> **ç›®æ ‡è¯»è€…**: Agent ç³»ç»Ÿæ¶æ„å¸ˆã€AI å·¥ç¨‹å¸ˆ
> **æ ¸å¿ƒå†…å®¹**: ä¸»æµæ¶æ„æ¨¡å¼ã€å·¥å…·ä½¿ç”¨æ¨¡å¼ã€è®°å¿†ç³»ç»Ÿ

---

## ä¸»æµæ¶æ„æ¨¡å¼

### æ¨¡å¼å¯¹æ¯”

| æ¶æ„æ¨¡å¼             | æ ¸å¿ƒæ€æƒ³                | é€‚ç”¨åœºæ™¯             | ä¼˜åŠ¿             | åŠ£åŠ¿               |
| :------------------- | :---------------------- | :------------------- | :--------------- | :----------------- |
| **ReAct**            | Reasoning + Acting å¾ªç¯ | å¤šæ­¥æ¨ç†ä»»åŠ¡         | ç›´è§‚ã€æ˜“å®ç°     | è¿­ä»£æ¬¡æ•°å¤šæ—¶å»¶è¿Ÿé«˜ |
| **Plan-and-Execute** | å…ˆè§„åˆ’åæ‰§è¡Œ            | å¤æ‚å¤šå·¥å…·ä»»åŠ¡       | æ‰§è¡Œé«˜æ•ˆã€å¯å¹¶è¡Œ | è§„åˆ’é˜¶æ®µé¢å¤–å¼€é”€   |
| **Reflexion**        | è‡ªæˆ‘åæ€ä¿®æ­£            | éœ€è¦é«˜è´¨é‡è¾“å‡ºçš„ä»»åŠ¡ | è¾“å‡ºè´¨é‡é«˜       | æˆæœ¬é«˜ã€é€Ÿåº¦æ…¢     |
| **Self-Consistency** | å¤šè·¯å¾„é‡‡æ ·æŠ•ç¥¨          | ä¸ç¡®å®šæ¨ç†ä»»åŠ¡       | æå‡å‡†ç¡®ç‡       | è®¡ç®—æˆæœ¬å€å¢       |
| **Direct Calling**   | åŸç”Ÿ Function Calling   | ç®€å•ä»»åŠ¡ (<3æ­¥)      | å¿«é€Ÿã€ä½æˆæœ¬     | ä¸é€‚åˆå¤æ‚ä»»åŠ¡     |
| **Hot-Multiplexing** | Stdin/Stdout æµå¤ç”¨     | é•¿è¿æ¥æŒä¹…åŒ–ä¼šè¯     | é›¶å†·å¯åŠ¨å»¶è¿Ÿ     | å†…å­˜å¸¸é©»           |

### æ¨¡å¼é€‰æ‹©æŒ‡å—

```
ä»»åŠ¡å¤æ‚åº¦åˆ¤æ–­ï¼š
â”‚
â”œâ”€ ç®€å• (< 3æ­¥)
â”‚   â””â”€ Direct Function Calling
â”‚
â”œâ”€ ä¸­ç­‰ (3-10æ­¥)
â”‚   â””â”€ ReAct Loop
â”‚
â”œâ”€ å¤æ‚å¤šå·¥å…·
â”‚   â””â”€ Plan-and-Execute
â”‚
â””â”€ é«˜è´¨é‡éœ€æ±‚
    â””â”€ Reflexion + Self-Consistency
```

---

## ReAct æ¨¡å¼

### ç»“æ„

```markdown
Thought: [åˆ†æå½“å‰çŠ¶æ€]
Action: [é€‰æ‹©å·¥å…·/è¡ŒåŠ¨]
Observation: [è§‚å¯Ÿç»“æœ]
... (é‡å¤)
Thought: [å¾—å‡ºç»“è®º]
Answer: [æœ€ç»ˆç­”æ¡ˆ]
```

### å®ç°

```yaml
# ReAct é…ç½®ç¤ºä¾‹
strategy: react
max_iterations: 10

system_prompt: |
  You are a helpful assistant.

  ## Instructions
  Think step by step before taking action.
  After each action, observe the result before proceeding.

  ## Format
  Thought: ...
  Action: tool_name(input=...)
  Observation: ...
```

---

## Plan-and-Execute æ¨¡å¼

### ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Phase 1: Planning          â”‚
â”‚  - åˆ†æä»»åŠ¡                          â”‚
â”‚  - æ‹†è§£å­ä»»åŠ¡                        â”‚
â”‚  - è¯†åˆ«ä¾èµ–å…³ç³»                      â”‚
â”‚  - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Phase 2: Execution           â”‚
â”‚  - æŒ‰è®¡åˆ’æ‰§è¡Œ                        â”‚
â”‚  - å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡                  â”‚
â”‚  - å¤„ç†æ‰§è¡Œç»“æœ                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®ç°

```yaml
# Plan-and-Execute é…ç½®ç¤ºä¾‹
strategy: planning
max_iterations: 15

system_prompt: |
  You are a planning expert.

  ## Phase 1: Planning
  1. Understand the user's goal
  2. Break down into sub-tasks
  3. Identify dependencies
  4. Create execution plan

  ## Phase 2: Execution
  1. Execute tasks according to plan
  2. Parallelize independent tasks
  3. Handle errors and adjust plan
```

---

## Reflexion æ¨¡å¼

### ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Step 1: Initial           â”‚
â”‚           ç”Ÿæˆåˆæ­¥ç­”æ¡ˆ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Step 2: Reflection          â”‚
â”‚  - è¯„ä¼°ç­”æ¡ˆè´¨é‡                      â”‚
â”‚  - è¯†åˆ«é—®é¢˜å’Œæ”¹è¿›ç©ºé—´                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Step 3: Refinement          â”‚
â”‚  - æ ¹æ®åæ€ç»“æœæ”¹è¿›ç­”æ¡ˆ              â”‚
â”‚  - ç”Ÿæˆæ›´ä¼˜ç‰ˆæœ¬                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®ç°

```yaml
# Reflexion é…ç½®ç¤ºä¾‹
strategy: reflexion
max_iterations: 3
quality_threshold: 0.8

system_prompt: |
  You are a quality-focused assistant.

  ## Workflow
  1. Generate initial response
  2. Reflect on quality:
     - Is the response accurate?
     - Is it complete?
     - What could be improved?
  3. Refine based on reflection
  4. Repeat until quality threshold met
```

---

## è®°å¿†ç³»ç»Ÿæ¶æ„

### ä¸‰å±‚è®°å¿†æ¨¡å‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    çŸ­æœŸè®°å¿† (Short-term)                 â”‚
â”‚  â€¢ å®¹é‡: 4K-32K tokens (å½“å‰ä¸Šä¸‹æ–‡çª—å£)                   â”‚
â”‚  â€¢ å­˜å‚¨: å†…å­˜ä¸­çš„æ¶ˆæ¯å†å²                                 â”‚
â”‚  â€¢ TTL: å•æ¬¡ä¼šè¯                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ å®šæœŸæ€»ç»“ + å‹ç¼©
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æƒ…æ™¯è®°å¿† (Episodic)                   â”‚
â”‚  â€¢ å®¹é‡: æ— é™ (å¯æŒä¹…åŒ–)                                  â”‚
â”‚  â€¢ å­˜å‚¨: PostgreSQL / Redis                              â”‚
â”‚  â€¢ ç´¢å¼•: å‘é‡ Embedding                                   â”‚
â”‚  â€¢ TTL: 30 å¤© (å¯é…ç½®)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ æå–å…³é”®ä¿¡æ¯
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é•¿æœŸè®°å¿† (Long-term)                   â”‚
â”‚  â€¢ å®¹é‡: æ— é™                                             â”‚
â”‚  â€¢ å­˜å‚¨: å‘é‡æ•°æ®åº“ + RAG                                 â”‚
â”‚  â€¢ ç´¢å¼•: pgvector / Redis Vector                          â”‚
â”‚  â€¢ TTL: æ°¸ä¹…                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®°å¿†æ£€ç´¢ç­–ç•¥

| ç­–ç•¥         | é€Ÿåº¦ | è´¨é‡ | é€‚ç”¨åœºæ™¯       |
| :----------- | :--- | :--- | :------------- |
| **æ»‘åŠ¨çª—å£** | å¿«   | ä½   | ç®€å•å¯¹è¯       |
| **è¯­ä¹‰æ£€ç´¢** | ä¸­   | ä¸­   | ä¸Šä¸‹æ–‡ç›¸å…³æŸ¥è¯¢ |
| **æ··åˆæ£€ç´¢** | æ…¢   | é«˜   | å¤æ‚æŸ¥è¯¢       |
| **é‡æ’åº**   | æœ€æ…¢ | æœ€é«˜ | ç²¾ç¡®ç­”æ¡ˆéœ€æ±‚   |

---

## å¤š Agent åä½œ

### åä½œæ¨¡å¼

| æ¨¡å¼         | æè¿°                  | é€‚ç”¨åœºæ™¯   |
| :----------- | :-------------------- | :--------- |
| **é¡ºåºåä½œ** | Agent ä¾æ¬¡å¤„ç†        | æµæ°´çº¿ä»»åŠ¡ |
| **å¹¶è¡Œåä½œ** | Agent åŒæ—¶å¤„ç†        | ç‹¬ç«‹å­ä»»åŠ¡ |
| **è¾©è®ºåä½œ** | Agent ç›¸äº’è¾©è®º        | å†³ç­–ä¼˜åŒ–   |
| **å±‚çº§åä½œ** | ä¸» Agent åè°ƒå­ Agent | å¤æ‚ç³»ç»Ÿ   |

### å±‚çº§åä½œæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Coordinator Agent                    â”‚
â”‚  â€¢ ä»»åŠ¡åˆ†è§£                                               â”‚
â”‚  â€¢ Agent é€‰æ‹©                                            â”‚
â”‚  â€¢ ç»“æœç»¼åˆ                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  Expert 1   â”‚ â”‚Expert 2â”‚ â”‚  Expert 3 â”‚
â”‚  (Domain A) â”‚ â”‚Domain Bâ”‚ â”‚  (Domain C)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æç¤ºè¯ vs ä»£ç ï¼šè¾¹ç•Œåˆ’åˆ†

### è¾¹ç•ŒçŸ©é˜µ

| èŒè´£         | æç¤ºè¯å æ¯” | ä»£ç å æ¯” | è¯´æ˜               |
| :----------- | :--------- | :------- | :----------------- |
| **è§’è‰²è¡Œä¸º** | 80%        | 20%      | ä¸»è¦é æç¤ºè¯å¼•å¯¼   |
| **å·¥å…·è°ƒç”¨** | 40%        | 60%      | ä»£ç è´Ÿè´£å®‰å…¨å’ŒéªŒè¯ |
| **æ•°æ®æµ**   | 20%        | 80%      | ä»£ç è´Ÿè´£å®ç°       |
| **è®°å¿†ç®¡ç†** | 30%        | 70%      | ä»£ç è´Ÿè´£å­˜å‚¨å’Œæ£€ç´¢ |
| **é”™è¯¯å¤„ç†** | 10%        | 90%      | ä»£ç è´Ÿè´£å®ç°       |

### åŸåˆ™

> **æç¤ºè¯ç”¨äº**: è¡Œä¸ºæŒ‡å¯¼ã€çµæ´»æ€§ã€å¯è§£é‡Šæ€§
> **ä»£ç ç”¨äº**: ç¡®å®šæ€§é€»è¾‘ã€æ€§èƒ½å…³é”®è·¯å¾„ã€å®‰å…¨æ€§

---

## å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

### 1. æç¤ºè¯è¿‡é•¿

**é—®é¢˜**: æç¤ºè¯å ç”¨å¤§é‡ä¸Šä¸‹æ–‡çª—å£

**è§£å†³æ–¹æ¡ˆ**:
- åˆ†å±‚æç¤ºè¯ï¼šåŸºç¡€è§’è‰² + åŠ¨æ€ä¸Šä¸‹æ–‡
- ä½¿ç”¨ç»“æ„åŒ–æ•°æ®æ›¿ä»£è‡ªç„¶è¯­è¨€
- æƒ°æ€§åŠ è½½ï¼šä»…åœ¨éœ€è¦æ—¶æ³¨å…¥è¯¦ç»†è¯´æ˜

### 2. æŒ‡ä»¤å†²çª

**é—®é¢˜**: ä¸åŒæ¨¡å—çš„æç¤ºè¯æŒ‡ä»¤äº’ç›¸å†²çª

**è§£å†³æ–¹æ¡ˆ**:
- å»ºç«‹æŒ‡ä»¤ä¼˜å…ˆçº§ï¼šå·¥å…·å±‚ > Agent å±‚ > å…¨å±€å±‚
- ä½¿ç”¨æ˜¾å¼è¦†ç›–æ ‡è®°
- åœ¨ä»£ç å±‚è¿›è¡Œå†²çªæ£€æµ‹

### 3. å¾ªç¯ä¾èµ–

**é—®é¢˜**: Agent A è°ƒç”¨ Agent Bï¼ŒAgent B åˆè°ƒç”¨ Agent A

**è§£å†³æ–¹æ¡ˆ**:
- è®¾è®¡æ—¶ç»˜åˆ¶ä¾èµ–å›¾ï¼Œæ£€æµ‹ç¯è·¯
- è®¾ç½®æœ€å¤§è°ƒç”¨æ·±åº¦
- ä½¿ç”¨è¶…æ—¶æœºåˆ¶

### 4. æç¤ºè¯æ³¨å…¥

**é—®é¢˜**: ç”¨æˆ·è¾“å…¥æ¶æ„æŒ‡ä»¤ç»•è¿‡å®‰å…¨æ£€æŸ¥

**è§£å†³æ–¹æ¡ˆ**:
- Action-Selector Pattern: å—é™çš„åŠ¨ä½œé€‰æ‹©å™¨
- Plan-Then-Execute Pattern: å…ˆè§„åˆ’å†æ‰§è¡Œ
- è¾“å…¥éªŒè¯å’Œè¿‡æ»¤
- æ²™ç®±åŒ–å·¥å…·æ‰§è¡Œ

---

## DivineSense é¡¹ç›®å®è·µ

### UniversalParrot æ¶æ„

```
UniversalParrot (é…ç½®é©±åŠ¨ç³»ç»Ÿ)
â”‚
â”œâ”€ ParrotFactory (å·¥å‚)
â”œâ”€ ParrotConfig (é…ç½®åŠ è½½)
â”‚
â”œâ”€ ExecutionStrategy (æ‰§è¡Œç­–ç•¥)
â”‚   â”œâ”€ DirectExecutor (åŸç”Ÿè°ƒç”¨)
â”‚   â”œâ”€ ReActExecutor (æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯)
â”‚   â””â”€ PlanningExecutor (ä¸¤é˜¶æ®µè§„åˆ’)
â”‚
â””â”€ ToolRegistry (å·¥å…·æ³¨å†Œè¡¨)
    â”œâ”€ memo_search
    â”œâ”€ schedule_add
    â”œâ”€ schedule_query
    â””â”€ find_free_time
```

### é…ç½®ç¤ºä¾‹

```yaml
# config/parrots/schedule.yaml
name: schedule
display_name: Schedule Parrot
emoji: "ğŸ“…"
strategy: direct
max_iterations: 5

tools:
  - schedule_add
  - schedule_query
  - schedule_update
  - find_free_time

system_prompt: |
  You are a helpful assistant for managing schedules and calendars.
  ...
```

---

## å»¶ä¼¸é˜…è¯»

- [AutoGen: Multi-Agent Conversation Framework](https://microsoft.github.io/autogen/)
- [MetaGPT: Multi-Agent Framework](https://github.com/geekan/MetaGPT)
- [Anthropic: Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)
