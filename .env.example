# ==============================================================================
# DivineSense 环境变量配置
# ==============================================================================
# 使用: cp .env.example .env && 编辑填入配置

# ==============================================================================
# [必填] 最小启动配置
# ==============================================================================

# 数据库 (AI 功能需要 PostgreSQL + pgvector)
# 开发环境默认配置 (匹配 docker/compose/dev.yml)
DIVINESENSE_DRIVER=postgres
DIVINESENSE_DSN=postgres://divinesense:divinesense@localhost:25432/divinesense?sslmode=disable

# 生产环境部署时，请修改为实际配置
# DIVINESENSE_DSN=postgres://divinesense:<your-password>@localhost:5432/divinesense?sslmode=disable

# AI 功能
DIVINESENSE_AI_ENABLED=true
DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-your-siliconflow-key
DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-your-deepseek-key

# ==============================================================================
# [可选] Geek Mode - Claude Code CLI 集成
# ==============================================================================
#
# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Geek Mode 允许用户在聊天中调用 Claude Code CLI 处理通用运维与开发任务          │
# │                                                                             │
# │ 核心能力 (不止于编码)：                                                       │
# │   • 💻 代码开发: 审查、修复 Bug、重构、单元测试、API 实现                     │
# │   • 🔍 系统运维: 日志分析、进程监控、网络排查、配置文件修改                    │
# │   • 📂 文件管理: 批量处理、格式转换、搜索替换、目录整理                        │
# │   • 🗄️ 数据维护: 数据库查询、备份恢复、数据迁移、ETL 脚本                     │
# │   • 🔄 自动化:  编写 Shell/Python 脚本、Git 操作、CI/CD 辅助                   │
# │                                                                             │
# │ 工作流程：                                                                   │
# │   1. 用户启用 Geek Mode (UI 开关)                                           │
# │   2. 发送自然语言指令 (不仅仅是关于代码)                                      │
# │   3. 系统自动调用 Claude Code Agent (基于 Shell/Go 插件)                     │
# │   4. 智能执行终端命令并返回结果                                              │
# └─────────────────────────────────────────────────────────────────────────────┘
#
# -----------------------------------------------------------------------------
# 前置条件
# -----------------------------------------------------------------------------
#
# 1. 安装 Claude Code CLI:
#    npm install -g @anthropic-ai/claude-code
#    或参考: https://github.com/anthropics/claude-code
#
# 2. 验证安装:
#    claude --version
#
# 3. 配置认证 (推荐使用智谱适配工具):
#    npx @z_ai/coding-helper
#    或者手动登录: claude auth login
#
# -----------------------------------------------------------------------------
# 环境变量配置
# -----------------------------------------------------------------------------
#
# 启用 Geek Mode:
DIVINESENSE_CLAUDE_CODE_ENABLED=false
#
# 启用 Evolution Mode (进化模式):
#   进化模式是 Geek Mode 的高级形态，解锁完整的 Claude Code Agent 能力
#   详见 EVOLUTION_MODE_SPEC.md
DIVINESENSE_EVOLUTION_ENABLED=false
#
# Evolution Mode 仅限管理员 (可选):
# DIVINESENSE_EVOLUTION_ADMIN_ONLY=true
#
# Docker 环境特殊说明:
#   • Docker 容器内需要安装 Claude Code CLI
#   • 建议在 Dockerfile 中添加:
#     RUN npm install -g @anthropic-ai/claude-code
#   • 工作目录默认挂载到 /var/opt/divinesense
#   • 确保容器有权限访问代码目录
#
# 本地开发环境:
#   • 直接设置 DIVINESENSE_CLAUDE_CODE_ENABLED=true
#   • 系统会使用当前工作目录作为代码操作目录
#   • 每个用户有独立的会话，文件变更限制为 100 次/会话
#   • 执行超时时间为 5 分钟
#
# -----------------------------------------------------------------------------
# 触发关键词 (自动检测)
# -----------------------------------------------------------------------------
#
# 中文: 代码, 函数, bug, 修复, 测试, 重构, 部署, 编程, 开发, 调试,
#       git, commit, 接口, api, 数据库, 查询, 算法, 优化
#
# English: code, function, bug, fix, test, refactor, deploy, program,
#          develop, debug, git, merge, branch, implement
#
# -----------------------------------------------------------------------------
# 示例对话
# -----------------------------------------------------------------------------
#
#   "帮我修复这段代码的 bug"
#   "重构这个函数，让它更高效"
#   "为这个 API 编写单元测试"
#   "检查 git commit 历史，找出最近引入的 bug"
#   "优化这个数据库查询"
#   "实现一个用户认证接口"
#
# -----------------------------------------------------------------------------
# 安全限制
# -----------------------------------------------------------------------------
#
#   • 每个用户独立会话，相互隔离
#   • 文件变更次数限制: 100 次/会话
#   • 执行超时: 5 分钟
#   • 所有文件操作限定在配置的工作目录内
#
# -----------------------------------------------------------------------------
# 故障排查
# -----------------------------------------------------------------------------
#
# 问题: "Geek Mode is disabled"
# 解决: 设置 DIVINESENSE_CLAUDE_CODE_ENABLED=true
#
# 问题: "Claude Code CLI not found"
# 解决: 确保系统已安装 claude 命令，且在 PATH 中
#
# 问题: Docker 容器内无法使用
# 解决: 在 Dockerfile 中添加 Claude Code CLI 安装步骤
#
# -----------------------------------------------------------------------------

# ==============================================================================
# [可选] AI 模型配置
# ==============================================================================
#
# 系统使用 4 类模型，各司其职：
#
# ┌──────────────┬──────────────────────────────────────────────────────────────┐
# │ 模型类型     │ 用途说明                                                     │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 对话 (LLM)   │ Agent 核心能力：对话、推理、工具调用                         │
# │              │ 场景：日程创建、笔记问答、综合分析                           │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 向量 (Embed) │ 文本向量化：将笔记转为向量存入 pgvector                      │
# │              │ 场景：语义搜索 "找关于项目管理的笔记"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 意图 (Intent)│ 用户输入分类：判断是创建/查询/修改日程                       │
# │              │ 场景：区分 "明天开会" vs "明天有空吗"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 重排 (Rerank)│ 搜索结果优化：对向量召回结果精排                             │
# │              │ 场景：提升搜索准确率，过滤无关结果                           │
# └──────────────┴──────────────────────────────────────────────────────────────┘
#
# 默认配置 (推荐):
#
# ┌──────────────┬────────────────┬──────────────────────────┬─────────────────┐
# │ 模型类型     │ Provider       │ 模型                     │ 使用的 API Key  │
# ├──────────────┼────────────────┼──────────────────────────┼─────────────────┤
# │ 对话 (LLM)   │ deepseek       │ deepseek-chat            │ DEEPSEEK_API_KEY│
# │ 向量 (Embed) │ siliconflow    │ BAAI/bge-m3              │ SILICONFLOW_KEY │
# │ 意图 (Intent)│ siliconflow    │ Qwen/Qwen2.5-7B-Instruct │ SILICONFLOW_KEY │
# │ 重排 (Rerank)│ siliconflow    │ BAAI/bge-reranker-v2-m3  │ SILICONFLOW_KEY │
# └──────────────┴────────────────┴──────────────────────────┴─────────────────┘
#
# 为什么这样分配？
# - DeepSeek: 对话能力强、推理深、工具调用稳定，适合做主 LLM
# - SiliconFlow: 向量/重排模型全、价格低、国内访问快，适合做基础设施
# - 意图分类用轻量 7B 模型：响应快(<500ms)、成本低、准确率高

# -----------------------------------------------------------------------------
# 自定义 Provider (按需修改)
# -----------------------------------------------------------------------------

# 向量 Provider: siliconflow (默认) | openai | ollama
# DIVINESENSE_AI_EMBEDDING_PROVIDER=siliconflow

# 对话 Provider: deepseek (默认) | openai | ollama | siliconflow
# DIVINESENSE_AI_LLM_PROVIDER=deepseek

# -----------------------------------------------------------------------------
# 自定义模型 (按需修改)
# -----------------------------------------------------------------------------

# 向量模型 (需与 Provider 匹配)
# DIVINESENSE_AI_EMBEDDING_MODEL=BAAI/bge-m3

# 重排模型 (固定使用 SiliconFlow)
# DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3

# 对话模型 (需与 Provider 匹配)
# DIVINESENSE_AI_LLM_MODEL=deepseek-chat

# 意图分类模型 (固定使用 SiliconFlow，无需配置)
# 默认: Qwen/Qwen2.5-7B-Instruct

# ==============================================================================
# [可选] 其他 Provider API Keys
# ==============================================================================

# OpenAI (如需使用 gpt-4o 等模型)
# DIVINESENSE_AI_OPENAI_API_KEY=sk-your-openai-key

# Ollama (本地部署)
# DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434

# ==============================================================================
# [可选] 附件处理
# ==============================================================================

# OCR 图片文字提取 (需安装 Tesseract)
# DIVINESENSE_OCR_ENABLED=true
# DIVINESENSE_OCR_LANGUAGES=chi_sim+eng

# 文档文本提取 (需部署 Apache Tika)
# DIVINESENSE_TEXTEXTRACT_ENABLED=true
# DIVINESENSE_TEXTEXTRACT_TIKA_URL=http://localhost:9998

# ==============================================================================
# 配置方案速查
# ==============================================================================
#
# 方案 A: SiliconFlow + DeepSeek [推荐]
# -------------------------------------
# 成本最优，国内访问稳定
# DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx
# DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-xxx
#
# 方案 B: 纯 SiliconFlow
# ----------------------
# 单一供应商，管理简单
# DIVINESENSE_AI_LLM_PROVIDER=siliconflow
# DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx
# DIVINESENSE_AI_LLM_MODEL=Qwen/Qwen2.5-72B-Instruct
#
# 方案 C: OpenAI 全家桶
# --------------------
# 海外用户，追求效果
# DIVINESENSE_AI_EMBEDDING_PROVIDER=openai
# DIVINESENSE_AI_LLM_PROVIDER=openai
# DIVINESENSE_AI_OPENAI_API_KEY=sk-xxx
# DIVINESENSE_AI_EMBEDDING_MODEL=text-embedding-3-small
# DIVINESENSE_AI_LLM_MODEL=gpt-4o
#
# 方案 D: 本地 Ollama
# ------------------
# 完全离线，数据私密
# DIVINESENSE_AI_EMBEDDING_PROVIDER=ollama
# DIVINESENSE_AI_LLM_PROVIDER=ollama
# DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434
# DIVINESENSE_AI_EMBEDDING_MODEL=nomic-embed-text
# DIVINESENSE_AI_LLM_MODEL=llama3.1

# ==============================================================================
# [二进制部署] 额外配置
# ==============================================================================
#
# 二进制部署安装位置:
#   - 二进制文件: /opt/divinesense/bin/divinesense
#   - 数据目录:   /opt/divinesense/data
#   - 配置文件:   /etc/divinesense/config
#   - 日志目录:   /opt/divinesense/logs
#
# 快速安装:
#   curl -fsSL https://raw.githubusercontent.com/hrygo/divinesense/main/deploy/aliyun/install.sh | sudo bash -s -- --mode=binary
#
# 详细文档: docs/deployment/BINARY_DEPLOYMENT.md
#
# 二进制部署时:
# 1. 复制此文件到 /etc/divinesense/config
# 2. 确保 DIVINESENSE_DATA 目录可写
# 3. 配置 PostgreSQL (Docker 或系统)
# 4. 运行: sudo systemctl enable --now divinesense
