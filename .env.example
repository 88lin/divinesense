# ==============================================================================
# DivineSense 环境变量配置
# ==============================================================================
# 使用: cp .env.example .env && 编辑填入配置

# ==============================================================================
# [必填] 最小启动配置
# ==============================================================================

# 数据库 (AI 功能需要 PostgreSQL + pgvector)
# 开发环境默认配置 (匹配 docker/compose/dev.yml)
DIVINESENSE_DRIVER=postgres
DIVINESENSE_DSN=postgres://divinesense:divinesense@localhost:25432/divinesense?sslmode=disable

# 生产环境部署时，请修改为实际配置
# DIVINESENSE_DSN=postgres://divinesense:<your-password>@localhost:5432/divinesense?sslmode=disable

# AI 功能
DIVINESENSE_AI_ENABLED=true
DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-your-siliconflow-key
DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-your-deepseek-key

# ==============================================================================
# [可选] Geek Mode - Claude Code CLI 集成
# ==============================================================================
#
# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Geek Mode 允许用户在聊天中调用 Claude Code CLI 处理通用运维与开发任务          │
# │                                                                             │
# │ 核心能力 (不止于编码)：                                                       │
# │   • 💻 代码开发: 审查、修复 Bug、重构、单元测试、API 实现                     │
# │   • 🔍 系统运维: 日志分析、进程监控、网络排查、配置文件修改                    │
# │   • 📂 文件管理: 批量处理、格式转换、搜索替换、目录整理                        │
# │   • 🗄️ 数据维护: 数据库查询、备份恢复、数据迁移、ETL 脚本                     │
# │   • 🔄 自动化:  编写 Shell/Python 脚本、Git 操作、CI/CD 辅助                   │
# │                                                                             │
# │ 工作流程：                                                                   │
# │   1. 用户启用 Geek Mode (UI 开关)                                           │
# │   2. 发送自然语言指令 (不仅仅是关于代码)                                      │
# │   3. 系统自动调用 Claude Code Agent (基于 Shell/Go 插件)                     │
# │   4. 智能执行终端命令并返回结果                                              │
# └─────────────────────────────────────────────────────────────────────────────┘
#
# -----------------------------------------------------------------------------
# 前置条件
# -----------------------------------------------------------------------------
#
# 1. 安装 Claude Code CLI:
#    npm install -g @anthropic-ai/claude-code
#    或参考: https://github.com/anthropics/claude-code
#
# 2. 验证安装:
#    claude --version
#
# 3. 配置认证 (推荐使用智谱适配工具):
#    npx @z_ai/coding-helper
#    或者手动登录: claude auth login
#
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# 环境变量配置
# -----------------------------------------------------------------------------
#
# 启用 Geek Mode:
#   设置此开关为 true 以开启 Geek Mode 功能模块。
#   开启后，用户可在前端界面通过独立开关（Switch）进入 Geek Mode。
#   进入该模式后的所有交互均由 Claude Code Agent 接管。
DIVINESENSE_CLAUDE_CODE_ENABLED=false
#
# Geek Mode 工作目录 (可选):
#   指定 Geek Mode 的沙箱及代码操作的基础目录。
#   每个用户的沙箱将创建在此目录下: {WORKDIR}/user_{id}
#   默认值: ~/.divinesense/claude
# DIVINESENSE_CLAUDE_CODE_WORKDIR=/opt/divinesense/data
##
# 启用 Evolution Mode (进化模式):
#   进化模式是 Geek Mode 的增强版，允许 Agent 自主修改项目核心代码。
#   注意：此模式权限极高，建议仅在受控环境开启。
DIVINESENSE_EVOLUTION_ENABLED=false
#
# Evolution Mode 仅限管理员 (可选):
# DIVINESENSE_EVOLUTION_ADMIN_ONLY=true
#
# Docker 环境特殊说明:
#   • Docker 容器内需要安装 Claude Code CLI
#   • 建议在 Dockerfile 中添加:
#     RUN npm install -g @anthropic-ai/claude-code
#   • 工作目录默认挂载到 /var/opt/divinesense
#   • 确保容器有权限访问代码目录
#
# 本地开发环境:
#   • 直接设置 DIVINESENSE_CLAUDE_CODE_ENABLED=true
#   • 系统会使用当前工作目录作为代码操作目录
#   • 每个用户有独立的会话，文件变更限制为 100 次/会话
#   • 执行超时时间为 5 分钟
#
# -----------------------------------------------------------------------------
# 使用示例
# -----------------------------------------------------------------------------
#
# 1. Geek Mode (沙箱环境 - 独立工作区):
#    "写一个 Python 脚本查询当前外网 IP 并保存到 ip.txt"
#    "帮我分析刚刚上传的 error.log 日志文件"
#    "生成一个 RSA 私钥并打印出来"
#    "列出当前目录下的所有文件"
#
# 2. Evolution Mode (进化模式 - 修改项目源码):
#    "为项目添加一个新的 API 接口: GET /api/v1/ping"
#    "修复 server/main.go 中的启动逻辑 bug"
#    "为 user_service.go 编写单元测试"
#    "检查 git status 并提交当前的更改"
#
# -----------------------------------------------------------------------------
# 安全限制
# -----------------------------------------------------------------------------
#
#   • 每个用户独立会话，相互隔离
#   • 文件变更次数限制: 100 次/会话
#   • 执行超时: 5 分钟
#   • 所有文件操作限定在配置的工作目录内
#
# -----------------------------------------------------------------------------
# 故障排查
# -----------------------------------------------------------------------------
#
# 问题: "Geek Mode is disabled"
# 解决: 设置 DIVINESENSE_CLAUDE_CODE_ENABLED=true
#
# 问题: "Claude Code CLI not found"
# 解决: 确保系统已安装 claude 命令，且在 PATH 中
#
# 问题: Docker 容器内无法使用
# 解决: 在 Dockerfile 中添加 Claude Code CLI 安装步骤
#
# -----------------------------------------------------------------------------

# ==============================================================================
# [可选] AI 缓存优化 - Issues #91, #92, #93
# ==============================================================================
#
# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ 三层缓存架构：提升响应速度、降低 API 成本、优化 Token 分配                     │
# │                                                                             │
# │ L1: 路由缓存 (ai/router/cache.go)                                          │
# │     • 意图分类结果缓存 (SHA256)                                              │
# │     • TTL: 规则 5min, LLM 30min                                              │
# │     • 容量: 500 条                                                           │
# │                                                                             │
# │ L2: 语义缓存 (ai/cache/semantic.go) - Issue #91                             │
# │     • Embedding 向量缓存 (精确匹配 + 语义相似度)                              │
# │     • 相似度阈值: 0.95 (可配置)                                              │
# │     • 容量: 1000 条, TTL: 24h                                               │
# │                                                                             │
# │ L3: 工具结果缓存 (ai/agent/tools/cache.go) - Issue #92                       │
# │     • 数据库查询结果缓存 (schedule_query, memo_search)                      │
# │     • 按 AgentType 配置 TTL                                                  │
# │     • 容量: 100 条 (可配置)                                                 │
# │                                                                             │
# │ Token 预算分配 (ai/context/budget_profiles.go) - Issue #93                    │
# │     • 按 AgentType 自适应分配 Token                                           │
# │     • 支持 7 种预设配置文件                                                   │
# │     • 环境变量覆盖支持                                                       │
# └─────────────────────────────────────────────────────────────────────────────┘
#
# -----------------------------------------------------------------------------
# 语义缓存配置 (Issue #91)
# -----------------------------------------------------------------------------
#
# 语义缓存使用两层查找机制：
#   1. 精确匹配：基于 SHA256 哈希，完全相同的查询直接命中
#   2. 语义匹配：基于余弦相似度，相似查询(≥阈值)复用 Embedding
#
# DIVINESENSE_SEMANTIC_CACHE_MAX_ENTRIES=1000
#   缓存最大条目数 (默认: 1000)
#
# DIVINESENSE_SEMANTIC_CACHE_SIMILARITY_THRESHOLD=0.95
#   语义相似度阈值 (0.0-1.0，默认: 0.95)
#   • 1.0 = 仅精确匹配
#   • 0.90 = 宽松匹配，更多命中但可能降低精度
#   • 0.95 = 推荐值，平衡命中率和准确性
#
# DIVINESENSE_SEMANTIC_CACHE_TTL=24h
#   缓存过期时间 (默认: 24h)
#   • 建议: 搜索类内容 1-7天，对话类 12-24h
#
# -----------------------------------------------------------------------------
# 工具结果缓存配置 (Issue #92)
# -----------------------------------------------------------------------------
#
# 工具结果缓存用于避免重复数据库查询：
#   • schedule_query: 30s (日程查询结果短期有效)
#   • memo_search: 5min (笔记搜索结果较稳定)
#   • find_free_time: 1min (空闲时间查询)
#   • schedule_add/update: 0 (写操作不缓存)
#
# DIVINESENSE_TOOL_CACHE_MAX_ENTRIES=100
#   工具缓存最大条目数 (默认: 100)
#
# DIVINESENSE_TOOL_CACHE_ENABLED=true
#   启用/禁用工具缓存 (默认: true)
#
# 工具级别 TTL 覆盖 (可选):
# DIVINESENSE_TOOL_CACHE_TTL_SCHEDULE_QUERY=30s
# DIVINESENSE_TOOL_CACHE_TTL_MEMO_SEARCH=5m
# DIVINESENSE_TOOL_CACHE_TTL_FIND_FREE_TIME=1m
#
# -----------------------------------------------------------------------------
# Token 预算分配配置 (Issue #93)
# -----------------------------------------------------------------------------
#
# 系统根据 AgentType 自动选择预算配置文件：
#
# ┌────────────────┬──────────────┬──────────────┬──────────────┬──────────────┐
# │ AgentType      │ ShortTerm    │ LongTerm     │ Retrieval    │ 说明         │
# │ (意图)         │ (近期对话)   │ (长期记忆)   │ (检索结果)   │              │
# ├────────────────┼──────────────┼──────────────┼──────────────┼──────────────┤
# │ memo_search    │ 30%          │ 10%          │ 60%          │ 检索优先     │
# │ schedule_query │ 55%          │ 25%          │ 20%          │ 对话为主     │
# │ schedule_create│ 55%          │ 25%          │ 20%          │ 对话为主     │
# │ amazing        │ 40%          │ 15%          │ 45%          │ 平衡分配     │
# │ geek           │ 0%           │ 0%           │ 0%           │ CC 管理      │
# │ evolution      │ 0%           │ 0%           │ 0%           │ CC 管理      │
# │ default        │ 40%          │ 15%          │ 45%          │ 默认配置     │
# └────────────────┴──────────────┴──────────────┴──────────────┴──────────────┘
#
# 注：剩余 10% 固定分配给用户偏好 (UserPrefs)
#     geek/evolution 使用 Claude Code CLI，上下文由 CLI 内部管理，无需分配预算
#
# 环境变量覆盖示例 (按需配置):
#
# # 调整 memo_search 的检索预算比例
# DIVINESENSE_BUDGET_MEMO_SEARCH_RETRIEVAL=0.70
# DIVINESENSE_BUDGET_MEMO_SEARCH_SHORT_TERM=0.25
# DIVINESENSE_BUDGET_MEMO_SEARCH_LONG_TERM=0.05
#
# # 调整 schedule_create 的对话预算比例
# DIVINESENSE_BUDGET_SCHEDULE_CREATE_SHORT_TERM=0.60
# DIVINESENSE_BUDGET_SCHEDULE_CREATE_LONG_TERM=0.30
# DIVINESENSE_BUDGET_SCHEDULE_CREATE_RETRIEVAL=0.10
#
# # 调整 amazing (综合助理) 的配置
# DIVINESENSE_BUDGET_AMAZING_RETRIEVAL=0.50
# DIVINESENSE_BUDGET_AMAZING_SHORT_TERM=0.35
# DIVINESENSE_BUDGET_AMAZING_LONG_TERM=0.15
#
# # 自定义新配置文件 (按需)
# DIVINESENSE_BUDGET_MY_PROFILE_SHORT_TERM=0.45
# DIVINESENSE_BUDGET_MY_PROFILE_LONG_TERM=0.20
# DIVINESENSE_BUDGET_MY_PROFILE_RETRIEVAL=0.35
#
# 预算计算公式：
#   SystemPrompt: 500 tokens (固定)
#   UserPrefs: 10% × TotalTokens
#   剩余预算 = TotalTokens - SystemPrompt - UserPrefs
#   各部分 = 剩余预算 × 对应比例
#
# -----------------------------------------------------------------------------
# 缓存效果预估
# -----------------------------------------------------------------------------
#
# 启用三层缓存后：
#
# • 路由缓存命中: ~0ms 延迟，节省意图分类 API 调用
# • 语义缓存命中: ~10ms 延迟，节省 Embedding API 调用
# • 工具缓存命中: ~1ms 延迟，节省数据库查询
#
# 成本节省 (假设 1000 次/日查询):
# • 意图分类: ~70% 命中率 → 节省 ~$0.50/日
# • Embedding: ~30% 命中率 → 节省 ~$0.30/日
# • 工具查询: ~40% 命中率 → 节省 ~$0.20/日
#
# 总计: ~$1.0/日 节省，月节省 ~$30
#
# -----------------------------------------------------------------------------

# ==============================================================================
# [可选] AI 模型配置
# ==============================================================================
#
# 系统使用 4 类模型，各司其职：
#
# ┌──────────────┬──────────────────────────────────────────────────────────────┐
# │ 模型类型     │ 用途说明                                                     │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 对话 (LLM)   │ Agent 核心能力：对话、推理、工具调用                         │
# │              │ 场景：日程创建、笔记问答、综合分析                           │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 向量 (Embed) │ 文本向量化：将笔记转为向量存入 pgvector                      │
# │              │ 场景：语义搜索 "找关于项目管理的笔记"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 意图 (Intent)│ 用户输入分类：判断是创建/查询/修改日程                       │
# │              │ 场景：区分 "明天开会" vs "明天有空吗"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 重排 (Rerank)│ 搜索结果优化：对向量召回结果精排                             │
# │              │ 场景：提升搜索准确率，过滤无关结果                           │
# └──────────────┴──────────────────────────────────────────────────────────────┘
#
# 默认配置 (推荐):
#
# ┌──────────────┬────────────────┬──────────────────────────┬─────────────────┐
# │ 模型类型     │ Provider       │ 模型                     │ 使用的 API Key  │
# ├──────────────┼────────────────┼──────────────────────────┼─────────────────┤
# │ 对话 (LLM)   │ deepseek       │ deepseek-chat            │ DEEPSEEK_API_KEY│
# │ 向量 (Embed) │ siliconflow    │ BAAI/bge-m3              │ SILICONFLOW_KEY │
# │ 意图 (Intent)│ siliconflow    │ Qwen/Qwen2.5-7B-Instruct │ SILICONFLOW_KEY │
# │ 重排 (Rerank)│ siliconflow    │ BAAI/bge-reranker-v2-m3  │ SILICONFLOW_KEY │
# └──────────────┴────────────────┴──────────────────────────┴─────────────────┘
#
# 为什么这样分配？
# - DeepSeek: 对话能力强、推理深、工具调用稳定，适合做主 LLM
# - SiliconFlow: 向量/重排模型全、价格低、国内访问快，适合做基础设施
# - 意图分类用轻量 7B 模型：响应快(<500ms)、成本低、准确率高

# -----------------------------------------------------------------------------
# 自定义 Provider (按需修改)
# -----------------------------------------------------------------------------

# 向量 Provider: siliconflow (默认) | openai | ollama
# DIVINESENSE_AI_EMBEDDING_PROVIDER=siliconflow

# 对话 Provider: deepseek (默认) | openai | ollama | siliconflow
# DIVINESENSE_AI_LLM_PROVIDER=deepseek

# -----------------------------------------------------------------------------
# 自定义模型 (按需修改)
# -----------------------------------------------------------------------------

# 向量模型 (需与 Provider 匹配)
# DIVINESENSE_AI_EMBEDDING_MODEL=BAAI/bge-m3

# 重排模型 (固定使用 SiliconFlow)
# DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3

# 对话模型 (需与 Provider 匹配)
# DIVINESENSE_AI_LLM_MODEL=deepseek-chat

# 意图分类模型 (固定使用 SiliconFlow，无需配置)
# 默认: Qwen/Qwen2.5-7B-Instruct

# ==============================================================================
# [可选] 其他 Provider API Keys
# ==============================================================================

# OpenAI (如需使用 gpt-4o 等模型)
# DIVINESENSE_AI_OPENAI_API_KEY=sk-your-openai-key

# Ollama (本地部署)
# DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434

# ==============================================================================
# [Chat Apps] 聊天应用集成 - 安全加密配置
# ==============================================================================
#
# 用于加密存储 Telegram, WhatsApp, DingTalk 的访问令牌 (Access Token/App Secret)
# 采用 AES-256-GCM 算法，要求密钥长度必须严格为 32 字节。
#
# ⚠️ 重要警告:
# 1. 如果启用了 Chat Apps 功能，此配置项为 **必需**。
# 2. 生产环境请生成一个独立的随机密钥。
#
# 生成命令:
#   openssl rand -base64 32 | cut -c1-32
#
# 示例:
# DIVINESENSE_CHAT_APPS_SECRET_KEY=change_me_to_a_random_32_byte_string
#
# 实例 URL (必需):
#   用于生成 Webhook URL，供聊天平台回调。
#   开发环境默认: http://localhost:28081
#   生产环境示例: https://your-domain.com
# DIVINESENSE_INSTANCE_URL=http://localhost:28081
#
# WhatsApp 桥接服务地址 (可选):
#   如果使用 WhatsApp，需要部署独立的 Baileys 桥接服务。
#   留空则表示不使用 WhatsApp 功能。
# DIVINESENSE_WHATSAPP_BRIDGE_URL=http://localhost:3001

# ==============================================================================
# [可选] 附件处理
# ==============================================================================

# OCR 图片文字提取 (需安装 Tesseract)
# DIVINESENSE_OCR_ENABLED=true
# DIVINESENSE_OCR_LANGUAGES=chi_sim+eng

# 文档文本提取 (需部署 Apache Tika)
# DIVINESENSE_TEXTEXTRACT_ENABLED=true
# DIVINESENSE_TEXTEXTRACT_TIKA_URL=http://localhost:9998

# ==============================================================================
# 配置方案速查
# ==============================================================================
#
# 方案 A: SiliconFlow + DeepSeek [推荐]
# -------------------------------------
# 成本最优，国内访问稳定
# DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx
# DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-xxx
#
# 方案 B: 纯 SiliconFlow
# ----------------------
# 单一供应商，管理简单
# DIVINESENSE_AI_LLM_PROVIDER=siliconflow
# DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx
# DIVINESENSE_AI_LLM_MODEL=Qwen/Qwen2.5-72B-Instruct
#
# 方案 C: OpenAI 全家桶
# --------------------
# 海外用户，追求效果
# DIVINESENSE_AI_EMBEDDING_PROVIDER=openai
# DIVINESENSE_AI_LLM_PROVIDER=openai
# DIVINESENSE_AI_OPENAI_API_KEY=sk-xxx
# DIVINESENSE_AI_EMBEDDING_MODEL=text-embedding-3-small
# DIVINESENSE_AI_LLM_MODEL=gpt-4o
#
# 方案 D: 本地 Ollama
# ------------------
# 完全离线，数据私密
# DIVINESENSE_AI_EMBEDDING_PROVIDER=ollama
# DIVINESENSE_AI_LLM_PROVIDER=ollama
# DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434
# DIVINESENSE_AI_EMBEDDING_MODEL=nomic-embed-text
# DIVINESENSE_AI_LLM_MODEL=llama3.1

# ==============================================================================
# [二进制部署] 额外配置
# ==============================================================================
#
# 二进制部署安装位置:
#   - 二进制文件: /opt/divinesense/bin/divinesense
#   - 数据目录:   /opt/divinesense/data
#   - 配置文件:   /etc/divinesense/config
#   - 日志目录:   /opt/divinesense/logs
#
# 快速安装:
#   curl -fsSL https://raw.githubusercontent.com/hrygo/divinesense/main/deploy/aliyun/install.sh | sudo bash -s -- --mode=binary
#
# 详细文档: docs/deployment/BINARY_DEPLOYMENT.md
#
# 二进制部署时:
# 1. 复制此文件到 /etc/divinesense/config
# 2. 确保 DIVINESENSE_DATA 目录可写
# 3. 配置 PostgreSQL (Docker 或系统)
# 4. 运行: sudo systemctl enable --now divinesense


