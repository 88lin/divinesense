# ==============================================================================
# DivineSense 环境变量配置
# ==============================================================================
# 使用: cp .env.example .env && 编辑填入配置
# ==============================================================================

# 一、快速开始 (最小配置)
# ==============================================================================
# 数据库 (AI 功能需要 PostgreSQL + pgvector)
DIVINESENSE_DRIVER=postgres
DIVINESENSE_DSN=postgres://divinesense:divinesense@localhost:25432/divinesense?sslmode=disable

# AI 功能开关
DIVINESENSE_AI_ENABLED=true

# ==============================================================================
# 二、AI 配置方案速查
# ==============================================================================
# ┌─────────────────────────────────────────────────────────────────────┐
# │ 方案 A: SiliconFlow + Z.AI GLM [★ 默认推荐]                              │
# │ ─────────────────────────────────────────────────────────────────────────── │
# │ 最佳组合：SiliconFlow 提供向量和重排，Z.AI 提供 GLM 对话             │
# │                                                                             │
# │ LLM:    GLM Opus 4.6 / Sonnet 5 (Z.AI 提供，国内稳定)              │
# │ Embed:  SiliconFlow BAAI/bge-m3                                             │
# │ Rerank:  SiliconFlow BAAI/bge-reranker-v2-m3                                 │
# │                                                                             │
# │ 配置:                                                                       │
# │   DIVINESENSE_AI_ZAI_API_KEY=sk-zai-xxx                                │
# │   DIVINESENSE_AI_ZAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4              │
# │   DIVINESENSE_AI_LLM_PROVIDER=zai                                         │
# │   DIVINESENSE_AI_LLM_MODEL=glm-5                                       │
# │   DIVINESENSE_AI_EMBEDDING_PROVIDER=siliconflow                             │
# │   DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx                                │
# │   DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3                      │
# └─────────────────────────────────────────────────────────────────────────────┘
# ┌─────────────────────────────────────────────────────────────────────┐
# │ 方案 B: SiliconFlow + DeepSeek                                             │
# │ ─────────────────────────────────────────────────────────────────── │
# │ 成本最优，国内访问稳定                                                      │
# │                                                                             │
# │ LLM:    DeepSeek V3.2                                                      │
# │ Embed:  SiliconFlow BAAI/bge-m3                                             │
# │ Rerank:  SiliconFlow BAAI/bge-reranker-v2-m3                                 │
# │                                                                             │
# │ 配置:                                                                       │
# │   DIVINESENSE_AI_LLM_PROVIDER=deepseek                                     │
# │   DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-xxx                                   │
# │   DIVINESENSE_AI_DEEPSEEK_BASE_URL=https://api.deepseek.com                   │
# │   DIVINESENSE_AI_EMBEDDING_PROVIDER=siliconflow                             │
# │   DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx                                │
# │   DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3                      │
# └─────────────────────────────────────────────────────────────────────────────┘
# ┌─────────────────────────────────────────────────────────────────────┐
# │ 方案 C: 纯 SiliconFlow                                                    │
# │ ─────────────────────────────────────────────────────────────────── │
# │ 单一供应商，管理简单                                                        │
# │                                                                             │
# │ LLM:    Qwen/Qwen2.5-72B-Instruct (也可用作对话)                       │
# │ Embed:  BAAI/bge-m3                                                        │
# │ Rerank:  BAAI/bge-reranker-v2-m3 (使用 SiliconFlow)                     │
# │                                                                             │
# │ 配置:                                                                       │
# │   DIVINESENSE_AI_LLM_PROVIDER=siliconflow                                  │
# │   DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-xxx                                │
# │   DIVINESENSE_AI_SILICONFLOW_BASE_URL=https://api.siliconflow.cn/v1               │
# │   DIVINESENSE_AI_LLM_MODEL=Qwen/Qwen2.5-72B-Instruct                   │
# │   DIVINESENSE_AI_EMBEDDING_MODEL=BAAI/bge-m3                                │
# │   DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3                      │
# └─────────────────────────────────────────────────────────────────────────────┘
# ┌─────────────────────────────────────────────────────────────────────┐
# │ 方案 D: OpenAI 全家桶                                                      │
# │ ─────────────────────────────────────────────────────────────────── │
# │ 海外用户，追求效果                                                          │
# │                                                                             │
# │ LLM:    gpt-4o                                                             │
# │ Embed:  text-embedding-3-small                                             │
# │                                                                             │
# │ 配置:                                                                       │
# │   DIVINESENSE_AI_LLM_PROVIDER=openai                                       │
# │   DIVINESENSE_AI_OPENAI_API_KEY=sk-xxx                                    │
# │   DIVINESENSE_AI_OPENAI_BASE_URL=https://api.openai.com/v1                   │
# │   DIVINESENSE_AI_EMBEDDING_MODEL=text-embedding-3-small                   │
# └─────────────────────────────────────────────────────────────────────────────┘
# ┌─────────────────────────────────────────────────────────────────────┐
# │ 方案 E: 本地 Ollama                                                       │
# │ ─────────────────────────────────────────────────────────────────── │
# │ 完全离线，数据私密                                                          │
# │                                                                             │
# │ LLM:    llama3.1 / qwen2.5                                              │
# │ Embed:  nomic-embed-text                                                    │
# │                                                                             │
# │ 配置:                                                                       │
# │   DIVINESENSE_AI_LLM_PROVIDER=ollama                                       │
# │   DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434                     │
# │   DIVINESENSE_AI_LLM_MODEL=llama3.1                                        │
# │   DIVINESENSE_AI_EMBEDDING_MODEL=nomic-embed-text                          │
# └─────────────────────────────────────────────────────────────────────────────┘

# ==============================================================================
# 三、Provider 选择 (可选值)
# ==============================================================================
# 对话 LLM:    deepseek | openai | siliconflow | zai | ollama
# 向量 Embed:  siliconflow | openai | ollama
# 意图 Intent:  (固定使用 siliconflow)

# ==============================================================================
# 四、Z.AI (智谱) 配置详解
# ==============================================================================
# 获取 API Key: https://open.bigmodel.cn/usercenter/apikeys
#
# 支持的模型 (GLM 系列):
#   • glm-4.7   (GLM Opus 4.6，推荐)
#   • glm-4.5   (GLM Sonnet 5，最新)
#   • glm-4-flash (GLM Flash，快速响应)
#   • glm-4-air  (GLM Air，极速)
#   • glm-4-plus (GLM Plus，增强版)
#
# Provider: zai
# Base URL: https://open.bigmodel.cn/api/paas/v4 (默认)
#
DIVINESENSE_AI_ZAI_API_KEY=sk-zai-your-key
DIVINESENSE_AI_ZAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4
DIVINESENSE_AI_LLM_PROVIDER=zai
DIVINESENSE_AI_LLM_MODEL=glm-4.7

# ==============================================================================
# 五、向量和重排配置 (方案 A 使用)
# ==============================================================================
DIVINESENSE_AI_EMBEDDING_PROVIDER=siliconflow
DIVINESENSE_AI_SILICONFLOW_API_KEY=sk-your-siliconflow-key
DIVINESENSE_AI_SILICONFLOW_BASE_URL=https://api.siliconflow.cn/v1
DIVINESENSE_AI_EMBEDDING_MODEL=BAAI/bge-m3
DIVINESENSE_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3

# ==============================================================================
# 六、DeepSeek 配置 (方案 B 使用)
# ==============================================================================
# 获取 API Key: https://platform.deepseek.com/api_keys
# 支持的模型: deepseek-chat (V3.2)
#
# DIVINESENSE_AI_LLM_PROVIDER=deepseek
# DIVINESENSE_AI_DEEPSEEK_API_KEY=sk-your-deepseek-key
# DIVINESENSE_AI_DEEPSEEK_BASE_URL=https://api.deepseek.com

# ==============================================================================
# 七、OpenAI 配置 (方案 D 使用)
# ==============================================================================
# 获取 API Key: https://platform.openai.com/api-keys
# 支持的模型: gpt-4o, gpt-4o-mini 等
#
# DIVINESENSE_AI_LLM_PROVIDER=openai
# DIVINESENSE_AI_OPENAI_API_KEY=sk-your-openai-key
# DIVINESENSE_AI_OPENAI_BASE_URL=https://api.openai.com/v1
# DIVINESENSE_AI_EMBEDDING_MODEL=text-embedding-3-small

# ==============================================================================
# 八、Ollama 配置 (方案 E 使用)
# ==============================================================================
# 安装: https://ollama.com
# 模型列表: https://ollama.com/search
#
# DIVINESENSE_AI_LLM_PROVIDER=ollama
# DIVINESENSE_AI_OLLAMA_BASE_URL=http://localhost:11434
# DIVINESENSE_AI_LLM_MODEL=llama3.1

# ==============================================================================
# 九、Attachment 处理配置
# ==============================================================================
DIVINESENSE_OCR_ENABLED=false
DIVINESENSE_TEXTEXTRACT_ENABLED=false
DIVINESENSE_OCR_TESSERACT_PATH=tesseract
DIVINESENSE_OCR_TESSDATA_PATH=""
DIVINESENSE_TEXTEXTRACT_TIKA_URL=http://localhost:9998

# ==============================================================================
# 十、其他配置
# ==============================================================================
# 服务端口 (默认: 后端 28081，前端 25173)
# PORT=5230

# 数据目录
# DATA_DIR=/var/lib/divinesense
