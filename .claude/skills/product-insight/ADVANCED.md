# HITL 交互设计

> Human-in-the-Loop：让 AI 成为思考伙伴，而非全自动工具

## 交互哲学

```
┌─────────────────────────────────────────────────────────────┐
│                    传统模式                                 │
│  输入 → AI 分析 → 输出 Issue                                  │
│  (人类无参与)                                                │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                    HITL 模式                                 │
│  输入 → AI 初步分析 ↔ 人类判断 → 深度分析 → 洞察产出    │
│  (关键决策点人类参与)                                        │
└─────────────────────────────────────────────────────────────┘
```

**核心原则**：
- AI 是"思考伙伴"，提供分析和选项
- 人类负责判断和决策
- 关键节点必须人类确认

## 四个关键交互点

### 交互点 1：分析方向选择

**触发**：发现多个值得深入的方向

```yaml
AI 提问:
  "发现了 3 个值得深入的方向：
   1. 成本优化模式（会话修剪）
   2. 可扩展性模式（插件系统）
   3. 本地化差异化机会

   你希望我："

人类选择:
  - 全部分析（推荐）→ AI 处理所有方向
  - 重点分析某个维度 → AI 聚焦指定方向
  - 快速模式 → 跳过部分交互，直接输出建议
```

### 交互点 2：模式验证

**触发**：抽象出新的模式或假设

```yaml
AI 提问:
  "我注意到一个模式：
   竞品的'会话修剪'、'记忆压缩'
   本质上都是同一个底层模式：

   【记忆成本管理】→ 在有限资源下最大化价值

   这个归纳准确吗？"

人类选择:
  - 准确，继续 → AI 按此模式分析
  - 部分准确 → AI 整合人类观点
  - 不准确，我认为是... → AI 重新归纳
```

### 交互点 3：战略判断

**触发**：需要判断"做/不做"时

```yaml
AI 提问:
  "关于'插件系统'功能：

   正方：用户定制化需求强
   反方：增加维护复杂度

   我的倾向：不做竞品那样的插件系统，
   而是优化现有工具接口（轻量方案）。

   你怎么看？"

人类选择:
  - 同意 → 更新战略建议
  - 不同意，我认为应该做 → AI 重新分析
  - 再给我更多分析 → 提供额外数据
```

### 交互点 4：优先级排序

**触发**：生成多个行动建议时

```yaml
AI 提问:
  "基于分析，我建议的优先级：
   P0: 本地记忆索引优化
   P1: 工具接口标准化

   你同意吗？"

人类选择:
  - 同意 → 继续生成 Issue
  - 调整 → 说明优先级变更
  - 需要更多信息 → AI 提供更多数据
```

## 交互模式控制

### 交互深度

```yaml
minimal:    # 仅关键决策（快速模式）
  - 战略方向确认
  - 做/不做判断

standard:   # 标准交互（默认，3-4 轮）
  - 分析方向选择
  - 战略判断（含模式验证）
  - 最终确认

deep:       # 深度交互（5+ 轮）
  - 每个阶段都确认
  - 邀请人类输入观点
  - 共同创造
```

### 智能交互

```yaml
自动确认（无需询问）:
  - 低价值判断（明显不适合的功能）
  - 已确认过的模式
  - 非关键的分析步骤

必须询问:
  - 战略方向变更
  - 做/不做判断
  - 高优先级任务
```

### 交互优化

- **默认轮次**: 3-4 轮（合并模式验证到战略判断）
- **快速模式**: 支持 "快速" / "信任你" 快捷指令
- **避免疲劳**: 同类问题合并，每次交互都有明确目的

## 快捷指令

| 指令 | 行为 | 示例 |
|:-----|:-----|:-----|
| "快速" | 跳过非关键交互 | "快速模式" |
| "信任你" | 使用 AI 所有建议 | "信任你，继续" |
| "深入 X" | 聚焦分析 | "深入插件系统" |
| "换个角度" | 尝试不同框架 | "换个角度分析" |
| "为什么" | 解释推理 | "为什么这样归纳？" |
| "确认" | 使用当前假设 | "确认，继续" |
| "调整：..." | 修正方向 | "调整：我觉得是..." |
| "跳过" | 跳过当前分析 | "跳过这个" |
| "总结" | 当前阶段总结 | "总结一下" |
| "完成" | 生成最终报告 | "完成" |

## 完整对话示例

```
────────────────────────────────────────────────────────────────
You: /product-insight

AI: 产品洞察分析启动。

    当前目标 SHA: abc1234 (+23 commits)

    发现的主要变化：
    • 新增：会话修剪功能
    • 增强：插件 SDK v2
    • 重构：Agent 路由机制

    我准备从以下维度深入分析：
    1. 成本优化模式（会话修剪）
    2. 可扩展性模式（插件系统）
    3. 本地化差异化机会

    你希望我：

────────────────────────────────────────────────────────────────
You: 全部分析

AI: 全部分析中...

    [分析过程...]

    关于"会话修剪"，我归纳出：
    【记忆成本管理】→ 在有限资源下最大化价值保留

    战略判断：
    • 竞品用时间修剪（旧 = 低价值）降低 API 成本
    • 我们无 API 成本压力，应差异化实现

    我的建议：基于语义相关性的本地检索（利用 pgvector）

    这是一个差异化机会，你希望：

────────────────────────────────────────────────────────────────
You: 同意，加入 P0

AI: 好，已加入 P0。

    [继续分析其他维度...]

    ┌─────────────────────────────────────────────────┐
    │  📊 战略建议                                    │
    ├─────────────────────────────────────────────────┤
    │  P0 (核心差异化):                              │
    │    • 本地记忆相关性检索（利用 pgvector）      │
    │  P1 (重要增强):                                │
    │    • 工具接口标准化                            │
    │  不做:                                         │
    │    • 主动对话修剪（我们无成本压力）            │
    │    • 多渠道集成（非个人场景）                  │
    └─────────────────────────────────────────────────┘

    同意这个优先级吗？

────────────────────────────────────────────────────────────────
You: 同意

AI: 分析完成，正在生成洞察报告...

    [输出报告]

    需要创建 Issue 吗？

────────────────────────────────────────────────────────────────
```

## 交互质量保证

### 设计原则

```
1. 每次交互都有明确目的
2. 选项简洁明确（≤ 4 个）
3. 人类可随时打断
4. AI 记住选择，不重复问
5. 人类可要求"解释推理"
```

### 质量指标

```
• 平均交互轮次：3-5 次
• 每轮理解时间：< 30 秒
• 人类满意度：70%+ 认可 AI 建议
```
