#!/usr/bin/env python3
"""
DivineSense æ–‡æ¡£ç®¡ç†è¾…åŠ©è„šæœ¬

ä¸º docs-manager skill æä¾›æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼š
1. Spec ID è‡ªåŠ¨ç”Ÿæˆ
2. æ™ºèƒ½åˆ†ç±»è§„åˆ™
3. é‡å¤å†…å®¹æ£€æµ‹
4. é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥
5. å¼•ç”¨å›¾æ„å»º

ä½¿ç”¨æ–¹å¼ï¼š
  python docs_helper.py check        # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
  python docs_helper.py refs        # æ„å»ºå¼•ç”¨å›¾
  python docs_helper.py next-spec   # ç”Ÿæˆä¸‹ä¸€ä¸ª Spec ID
  python docs_helper.py duplicates  # æ£€æµ‹é‡å¤å†…å®¹
"""

import os
import re
import sys
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Set, Tuple
from collections import defaultdict
import difflib

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
DOCS_DIR = PROJECT_ROOT / "docs"


@dataclass
class Reference:
    """æ–‡æ¡£å¼•ç”¨"""
    source: str      # å¼•ç”¨æºæ–‡ä»¶
    target: str      # è¢«å¼•ç”¨æ–‡ä»¶
    line: int        # è¡Œå·
    ref_type: str    # å¼•ç”¨ç±»å‹: markdown, at_syntax, absolute_url, plain
    context: str     # ä¸Šä¸‹æ–‡


@dataclass
class DocNode:
    """æ–‡æ¡£èŠ‚ç‚¹"""
    path: str                      # æ–‡æ¡£è·¯å¾„
    references: List[Reference] = field(default_factory=list)  # å¼•ç”¨
    referenced_by: List[str] = field(default_factory=list)     # åå‘å¼•ç”¨


def glob_docs(pattern: str = "**/*.md") -> List[Path]:
    """æ‰«ææ–‡æ¡£æ–‡ä»¶"""
    return list(DOCS_DIR.rglob(pattern))


def extract_references(file_path: Path) -> List[Reference]:
    """ä»æ–‡ä»¶ä¸­æå–æ‰€æœ‰å¼•ç”¨"""
    references = []
    content = file_path.read_text(encoding="utf-8", errors="ignore")
    lines = content.split("\n")

    # å¼•ç”¨æ­£åˆ™æ¨¡å¼
    patterns = [
        # Markdown é“¾æ¥: [text](docs/xxx.md) æˆ– [text](../docs/xxx.md)
        (r"\[([^\]]+)\]\((docs/[^)]+\.md)\)", "markdown"),
        (r"\[([^\]]+)\]\(\.\./(docs/[^)]+\.md)\)", "markdown"),
        # @ è¯­æ³•: @docs/dev-guides/ARCHITECTURE.md
        (r"@docs/[\w/-]+\.md", "at_syntax"),
        # ç»å¯¹ URL
        (r"https://github\.com/[^)]+/docs/[\w/-]+\.md", "absolute_url"),
        # ä»£ç æ³¨é‡Šä¸­çš„å¼•ç”¨
        (r"[è¯¦è§å‚è€ƒ]*[`â€˜]docs/[\w/-]+\.md[`â€™]", "plain"),
    ]

    for line_no, line in enumerate(lines, 1):
        for pattern, ref_type in patterns:
            for match in re.finditer(pattern, line):
                target = match.group(0)
                # æ¸…ç†ç›®æ ‡è·¯å¾„
                if ref_type == "at_syntax":
                    target = target.replace("@", "")
                elif ref_type == "plain":
                    target = re.search(r"docs/[\w/-]+\.md", target).group(0)
                elif ref_type == "absolute_url":
                    target = "/docs/" + target.split("/docs/")[-1]

                references.append(Reference(
                    source=str(file_path.relative_to(PROJECT_ROOT)),
                    target=target,
                    line=line_no,
                    ref_type=ref_type,
                    context=line.strip()
                ))

    return references


def build_reference_graph() -> Dict[str, DocNode]:
    """æ„å»ºæ–‡æ¡£å¼•ç”¨å›¾"""
    graph = {}

    for doc_file in glob_docs():
        rel_path = str(doc_file.relative_to(DOCS_DIR))
        node = DocNode(path=rel_path)
        node.references = extract_references(doc_file)
        graph[rel_path] = node

    # æ„å»ºåå‘å¼•ç”¨
    for path, node in graph.items():
        for ref in node.references:
            # æ ‡å‡†åŒ–ç›®æ ‡è·¯å¾„
            target = ref.target
            if target.startswith("docs/"):
                target = target[5:]
            elif target.startswith("../docs/"):
                target = target[8:]

            if target in graph:
                if path not in graph[target].referenced_by:
                    graph[target].referenced_by.append(path)

    return graph


def check_links() -> Dict[str, List[str]]:
    """æ£€æŸ¥é“¾æ¥æœ‰æ•ˆæ€§"""
    issues = defaultdict(list)
    graph = build_reference_graph()

    # è·å–æ‰€æœ‰å­˜åœ¨çš„æ–‡æ¡£
    existing_docs = set(graph.keys())

    for path, node in graph.items():
        for ref in node.references:
            target = ref.target
            # æ ‡å‡†åŒ–
            if target.startswith("docs/"):
                target = target[5:]
            elif target.startswith("../docs/"):
                target = target[8:]

            if target not in existing_docs:
                issues["broken_links"].append(
                    f"{path}:{ref.line} -> {target} ({ref.ref_type})"
                )

    return issues


def get_next_spec_id(phase: int, team: str) -> str:
    """ç”Ÿæˆä¸‹ä¸€ä¸ª Spec ID"""
    pattern = f"docs/specs/phase-{phase}/team-{team}/P{phase}-{team}*.md"
    existing = list(PROJECT_ROOT.glob(pattern))

    if not existing:
        return f"P{phase}-{team}001"

    max_id = 0
    for f in existing:
        match = re.search(rf"P{phase}-{team}(\d+)", f.name)
        if match:
            max_id = max(max_id, int(match.group(1)))

    return f"P{phase}-{team}{max_id + 1:03d}"


def detect_duplicates(threshold: float = 0.7) -> List[Tuple[str, str, float]]:
    """æ£€æµ‹é‡å¤å†…å®¹"""
    duplicates = []
    docs = glob_docs()

    # è¯»å–æ‰€æœ‰æ–‡æ¡£å†…å®¹
    contents = {}
    for doc in docs:
        if "archived" in str(doc) or "node_modules" in str(doc):
            continue
        try:
            content = doc.read_text(encoding="utf-8", errors="ignore")
            # ç§»é™¤ç©ºç™½è¡Œï¼Œä¿ç•™å†…å®¹ç»“æ„
            lines = [l.strip() for l in content.split("\n") if l.strip()]
            contents[doc] = " ".join(lines)
        except:
            pass

    # ä¸¤ä¸¤æ¯”è¾ƒ
    doc_list = list(contents.items())
    for i in range(len(doc_list)):
        for j in range(i + 1, len(doc_list)):
            doc1, content1 = doc_list[i]
            doc2, content2 = doc_list[j]

            # ä½¿ç”¨ SequenceMatcher è®¡ç®—ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(
                None, content1, content2
            ).ratio()

            if similarity >= threshold:
                duplicates.append((
                    str(doc1.relative_to(DOCS_DIR)),
                    str(doc2.relative_to(DOCS_DIR)),
                    similarity
                ))

    return sorted(duplicates, key=lambda x: -x[2])


def classify_document(file_path: Path) -> Tuple[str, str]:
    """æ™ºèƒ½åˆ†ç±»æ–‡æ¡£"""
    name = file_path.name
    rel_path = str(file_path.relative_to(DOCS_DIR))

    # ç ”ç©¶æ–‡æ¡£åˆ†ç±»
    if name.startswith("00-"):
        return "core", "æ ¸å¿ƒè·¯çº¿å›¾"
    if name.endswith("-research.md"):
        return "reports", "ç ”ç©¶æŠ¥å‘Š"
    if name.endswith("-roadmap.md"):
        return "roadmaps", "è·¯çº¿å›¾"
    if "PRACTICE" in name or name == "DEBUG_LESSONS.md":
        return "practices", "æœ€ä½³å®è·µ"

    # Spec åˆ†ç±»
    spec_match = re.match(r"phase-(\d)/team-([abc])/", rel_path)
    if spec_match:
        phase, team = spec_match.groups()
        return f"Phase {phase}", f"Team {team.upper()}"

    return "other", "å…¶ä»–"


def main():
    """ä¸»å…¥å£"""
    command = sys.argv[1] if len(sys.argv) > 1 else "check"

    if command == "check":
        print("ğŸ“‹ æ–‡æ¡£æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 50)

        issues = check_links()

        if issues["broken_links"]:
            print(f"\nâœ— æ–­é“¾ ({len(issues['broken_links'])}):")
            for issue in issues["broken_links"]:
                print(f"  ğŸ”— {issue}")
        else:
            print("\nâœ“ æ— æ–­é“¾")

    elif command == "refs":
        print("ğŸ”— å¼•ç”¨å…³ç³»å›¾")
        print("=" * 50)

        graph = build_reference_graph()

        for path, node in sorted(graph.items()):
            if node.references:
                print(f"\n{path}:")
                print(f"  å¼•ç”¨: {len(node.references)} ä¸ª")
                print(f"  è¢«å¼•ç”¨: {len(node.referenced_by)} æ¬¡")

    elif command == "next-spec":
        phase = int(sys.argv[2]) if len(sys.argv) > 2 else 2
        team = sys.argv[3] if len(sys.argv) > 3 else "a"
        spec_id = get_next_spec_id(phase, team)
        print(f"ğŸ“„ ä¸‹ä¸€ä¸ª Spec ID: {spec_id}")

    elif command == "duplicates":
        print("ğŸ” é‡å¤å†…å®¹æ£€æµ‹")
        print("=" * 50)

        dupes = detect_duplicates()

        if dupes:
            for doc1, doc2, sim in dupes[:10]:
                print(f"\n{sim:.1%} ç›¸ä¼¼åº¦:")
                print(f"  1. {doc1}")
                print(f"  2. {doc2}")
        else:
            print("\nâœ“ æ— é‡å¤å†…å®¹")

    else:
        print(f"æœªçŸ¥å‘½ä»¤: {command}")
        print("å¯ç”¨å‘½ä»¤: check, refs, next-spec, duplicates")
        sys.exit(1)


if __name__ == "__main__":
    main()
