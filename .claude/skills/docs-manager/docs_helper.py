#!/usr/bin/env python3
"""
DivineSense æ–‡æ¡£ç®¡ç†è¾…åŠ©è„šæœ¬ v2.0

ä¸º docs-manager skill æä¾›æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼š
1. Spec ID è‡ªåŠ¨ç”Ÿæˆ
2. æ™ºèƒ½åˆ†ç±»è§„åˆ™
3. é‡å¤å†…å®¹æ£€æµ‹ (ä¼˜åŒ–ç‰ˆ)
4. é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥
5. å¼•ç”¨å›¾æ„å»º
6. JSON è¾“å‡ºæ¨¡å¼ (AI å‹å¥½)

ä½¿ç”¨æ–¹å¼ï¼š
  python docs_helper.py check        # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
  python docs_helper.py refs        # æ„å»ºå¼•ç”¨å›¾
  python docs_helper.py refs --json # JSON è¾“å‡º
  python docs_helper.py next-spec   # ç”Ÿæˆä¸‹ä¸€ä¸ª Spec ID
  python docs_helper.py duplicates  # æ£€æµ‹é‡å¤å†…å®¹
"""

import argparse
import json
import logging
import os
import re
import sys
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import difflib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s: %(message)s'
)
logger = logging.getLogger(__name__)


def find_project_root() -> Path:
    """é€šè¿‡ .git ç›®å½•æˆ– go.mod å®šä½é¡¹ç›®æ ¹ç›®å½•"""
    # ä»å½“å‰è„šæœ¬å¼€å§‹å‘ä¸ŠæŸ¥æ‰¾
    current = Path(__file__).resolve().parent
    max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯

    for _ in range(max_iterations):
        # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æ˜¯é¡¹ç›®æ ¹ï¼ˆæœ‰ .git æˆ– go.modï¼‰
        if (current / ".git").exists():
            return current
        if (current / "go.mod").exists():
            return current
        if (current / "CLAUDE.md").exists():  # DivineSense ç‰¹æœ‰æ–‡ä»¶
            return current

        # å‘ä¸Šä¸€å±‚
        current = current.parent

    # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨å›ºå®šæ·±åº¦
    # .claude/skills/docs-manager/docs_helper.py â†’ é¡¹ç›®æ ¹ = 4 å±‚å‘ä¸Š
    return Path(__file__).parent.parent.parent.parent


PROJECT_ROOT = find_project_root()
DOCS_DIR = PROJECT_ROOT / "docs"

logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
logger.info(f"æ–‡æ¡£ç›®å½•: {DOCS_DIR}")


@dataclass
class Reference:
    """æ–‡æ¡£å¼•ç”¨"""
    source: str      # å¼•ç”¨æºæ–‡ä»¶
    target: str      # è¢«å¼•ç”¨æ–‡ä»¶
    line: int        # è¡Œå·
    ref_type: str    # å¼•ç”¨ç±»å‹
    context: str     # ä¸Šä¸‹æ–‡


@dataclass
class DocNode:
    """æ–‡æ¡£èŠ‚ç‚¹"""
    path: str
    references: List[dict] = None
    referenced_by: List[str] = None

    def __post_init__(self):
        if self.references is None:
            self.references = []
        if self.referenced_by is None:
            self.referenced_by = []


def glob_docs(pattern: str = "**/*.md") -> List[Path]:
    """æ‰«ææ–‡æ¡£æ–‡ä»¶ï¼Œæ’é™¤ node_modules"""
    docs = []
    for doc in DOCS_DIR.rglob(pattern):
        # æ’é™¤ä¸éœ€è¦çš„ç›®å½•
        if "node_modules" in str(doc):
            continue
        docs.append(doc)
    return docs


def extract_references(file_path: Path) -> List[Reference]:
    """ä»æ–‡ä»¶ä¸­æå–æ‰€æœ‰å¼•ç”¨"""
    references = []

    try:
        content = file_path.read_text(encoding="utf-8")
    except PermissionError:
        logger.warning(f"æ— æƒé™è¯»å–: {file_path}")
        return references
    except UnicodeDecodeError:
        logger.warning(f"ç¼–ç é”™è¯¯: {file_path}")
        return references
    except Exception as e:
        logger.error(f"è¯»å–å¤±è´¥ {file_path}: {e}")
        return references

    lines = content.split("\n")

    # æ”¹è¿›çš„å¼•ç”¨æ­£åˆ™æ¨¡å¼
    patterns = [
        # Markdown é“¾æ¥
        (r"\[([^\]]+)\]\((docs/[^)]+\.md)\)", "markdown"),
        (r"\[([^\]]+)\]\(\.\./(docs/[^)]+\.md)\)", "markdown"),
        # @ è¯­æ³•
        (r"@docs/[\w/-]+\.md", "at_syntax"),
        # ç»å¯¹ URL
        (r"https://github\.com/[^/]+/[^/]+/docs/[\w/-]+\.md", "absolute_url"),
        # ä»£ç æ³¨é‡Š - æ”¹è¿›çš„æ­£åˆ™
        (r"(?:[\u8be6\u89c1\u53c2\u8003]+|see|refer to)\s+[`'\"()]?docs/[\w/-]+\.md", "plain"),
    ]

    for line_no, line in enumerate(lines, 1):
        for pattern, ref_type in patterns:
            try:
                for match in re.finditer(pattern, line, re.IGNORECASE):
                    target = match.group(0)

                    # æ¸…ç†ç›®æ ‡è·¯å¾„
                    if ref_type == "at_syntax":
                        target = target.replace("@", "")
                    elif ref_type == "plain":
                        # æå– docs/xxx.md éƒ¨åˆ†
                        doc_match = re.search(r"docs/[\w/-]+\.md", target)
                        if doc_match:
                            target = doc_match.group(0)
                        else:
                            continue
                    elif ref_type == "absolute_url":
                        target = "/docs/" + target.split("/docs/")[-1]

                    references.append(Reference(
                        source=str(file_path.relative_to(PROJECT_ROOT)),
                        target=target,
                        line=line_no,
                        ref_type=ref_type,
                        context=line.strip()[:80]
                    ))
            except Exception as e:
                logger.debug(f"æ­£åˆ™åŒ¹é…å¤±è´¥: {e}")

    return references


def build_reference_graph() -> Dict[str, DocNode]:
    """æ„å»ºæ–‡æ¡£å¼•ç”¨å›¾"""
    graph = {}
    docs = glob_docs()

    logger.info(f"æ‰«æ {len(docs)} ä¸ªæ–‡æ¡£...")

    for doc_file in docs:
        try:
            rel_path = str(doc_file.relative_to(DOCS_DIR))
            node = DocNode(path=rel_path)

            refs = extract_references(doc_file)
            for ref in refs:
                node.references.append({
                    "target": ref.target,
                    "type": ref.ref_type,
                    "line": ref.line,
                    "context": ref.context
                })

            graph[rel_path] = node
        except Exception as e:
            logger.warning(f"å¤„ç†æ–‡æ¡£å¤±è´¥ {doc_file}: {e}")

    # æ„å»ºåå‘å¼•ç”¨
    for path, node in graph.items():
        for ref in node.references:
            target = ref["target"]
            # æ ‡å‡†åŒ–è·¯å¾„
            if target.startswith("docs/"):
                target = target[5:]
            elif target.startswith("../docs/"):
                target = target[8:]
            elif target.startswith("/docs/"):
                target = target[6:]

            if target in graph:
                if path not in graph[target].referenced_by:
                    graph[target].referenced_by.append(path)

    return graph


def check_links() -> Dict[str, List[str]]:
    """æ£€æŸ¥é“¾æ¥æœ‰æ•ˆæ€§"""
    issues = defaultdict(list)
    graph = build_reference_graph()
    existing_docs = set(graph.keys())

    for path, node in graph.items():
        for ref in node.references:
            target = ref["target"]
            # æ ‡å‡†åŒ–
            if target.startswith("docs/"):
                target = target[5:]
            elif target.startswith("../docs/"):
                target = target[8:]
            elif target.startswith("/docs/"):
                target = target[6:]

            if target not in existing_docs:
                issues["broken_links"].append({
                    "source": path,
                    "line": ref["line"],
                    "target": target,
                    "type": ref["type"]
                })

    return dict(issues)


def get_next_spec_id(phase: int, team: str) -> str:
    """ç”Ÿæˆä¸‹ä¸€ä¸ª Spec ID"""
    pattern = f"P{phase}-{team}*.md"
    team_dir = DOCS_DIR / "specs" / f"phase-{phase}" / f"team-{team}"

    if not team_dir.exists():
        return f"P{phase}-{team}001"

    existing = list(team_dir.glob(pattern))

    if not existing:
        return f"P{phase}-{team}001"

    max_id = 0
    for f in existing:
        match = re.search(rf"P{phase}-{team}(\d+)", f.stem)
        if match:
            max_id = max(max_id, int(match.group(1)))

    return f"P{phase}-{team}{max_id + 1:03d}"


def detect_duplicates_fast(threshold: float = 0.7) -> List[Tuple[str, str, float]]:
    """å¿«é€Ÿæ£€æµ‹é‡å¤å†…å®¹ - ä»…æ£€æŸ¥å‰ 1000 ä¸ªå­—ç¬¦"""
    duplicates = []
    docs = glob_docs()
    contents = {}

    # è¿‡æ»¤å’Œé¢„å¤„ç†
    for doc in docs:
        if "archived" in str(doc) or "node_modules" in str(doc):
            continue
        try:
            content = doc.read_text(encoding="utf-8", errors="ignore")
            # åªå–å‰ 1000 å­—ç¬¦å¿«é€Ÿæ£€æµ‹
            preview = content[:1000]
            lines = [l.strip() for l in preview.split("\n") if l.strip()]
            contents[doc] = " ".join(lines)
        except Exception:
            pass

    # ä¸¤ä¸¤æ¯”è¾ƒ (ä»…é¢„è§ˆ)
    doc_list = list(contents.items())
    for i in range(len(doc_list)):
        for j in range(i + 1, len(doc_list)):
            doc1, content1 = doc_list[i]
            doc2, content2 = doc_list[j]

            similarity = difflib.SequenceMatcher(None, content1, content2).ratio()

            if similarity >= threshold:
                duplicates.append((
                    str(doc1.relative_to(DOCS_DIR)),
                    str(doc2.relative_to(DOCS_DIR)),
                    similarity
                ))

    return sorted(duplicates, key=lambda x: -x[2])


def classify_document(file_path: Path) -> Tuple[str, str]:
    """æ™ºèƒ½åˆ†ç±»æ–‡æ¡£"""
    name = file_path.name
    rel_path = str(file_path.relative_to(DOCS_DIR))

    if name.startswith("00-"):
        return "core", "æ ¸å¿ƒè·¯çº¿å›¾"
    if name.endswith("-research.md"):
        return "reports", "ç ”ç©¶æŠ¥å‘Š"
    if name.endswith("-roadmap.md"):
        return "roadmaps", "è·¯çº¿å›¾"
    if "PRACTICE" in name or name == "DEBUG_LESSONS.md":
        return "practices", "æœ€ä½³å®è·µ"

    spec_match = re.match(r"phase-(\d)/team-([abc])/", rel_path)
    if spec_match:
        phase, team = spec_match.groups()
        return f"Phase {phase}", f"Team {team.upper()}"

    return "other", "å…¶ä»–"


def print_refs_table(graph: Dict[str, DocNode]):
    """æ‰“å°å¼•ç”¨å…³ç³»è¡¨"""
    # æŒ‰è¢«å¼•ç”¨æ¬¡æ•°æ’åº
    hot_docs = sorted(
        [(path, len(node.referenced_by)) for path, node in graph.items()],
        key=lambda x: -x[1]
    )[:10]

    print("\nğŸ”¥ çƒ­é—¨æ–‡æ¡£ (è¢«å¼•ç”¨æœ€å¤š):")
    for path, count in hot_docs:
        if count > 0:
            print(f"  {count:2d} â† {path}")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(description="DivineSense æ–‡æ¡£ç®¡ç†å·¥å…·")
    parser.add_argument("command", nargs="?", default="check",
                       choices=["check", "refs", "next-spec", "duplicates", "tree"],
                       help="å‘½ä»¤")
    parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    parser.add_argument("--phase", type=int, help="Phase (next-spec)")
    parser.add_argument("--team", type=str, help="Team (next-spec)")

    args = parser.parse_args()
    command = args.command

    if command == "check":
        print("ğŸ“‹ æ–‡æ¡£æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 50)

        issues = check_links()
        broken = issues.get("broken_links", [])

        if args.json:
            print(json.dumps(broken, indent=2, ensure_ascii=False))
        elif broken:
            print(f"\nâœ— æ–­é“¾ ({len(broken)}):")
            for issue in broken:
                src = issue['source']
                line = issue['line']
                tgt = issue['target']
                print(f"  ğŸ”— {src}:{line} â†’ {tgt}")
        else:
            print("\nâœ“ æ— æ–­é“¾")

    elif command == "refs":
        print("ğŸ”— å¼•ç”¨å…³ç³»å›¾")
        print("=" * 50)

        graph = build_reference_graph()

        if args.json:
            # è½¬æ¢ä¸º JSON å¯åºåˆ—åŒ–æ ¼å¼
            output = {}
            for path, node in graph.items():
                output[path] = {
                    "references": node.references,
                    "referenced_by": node.referenced_by
                }
            print(json.dumps(output, indent=2, ensure_ascii=False))
        else:
            for path, node in sorted(graph.items()):
                if node.references or node.referenced_by:
                    print(f"\n{path}:")
                    print(f"  å¼•ç”¨: {len(node.references)} ä¸ª")
                    print(f"  è¢«å¼•ç”¨: {len(node.referenced_by)} æ¬¡")

            print_refs_table(graph)

    elif command == "next-spec":
        phase = args.phase or 2
        team = args.team or "a"
        spec_id = get_next_spec_id(phase, team)

        if args.json:
            print(json.dumps({"spec_id": spec_id, "phase": phase, "team": team}))
        else:
            print(f"ğŸ“„ ä¸‹ä¸€ä¸ª Spec ID: {spec_id}")

    elif command == "duplicates":
        print("ğŸ” é‡å¤å†…å®¹æ£€æµ‹")
        print("=" * 50)

        dupes = detect_duplicates_fast()

        if args.json:
            print(json.dumps(dupes, indent=2))
        elif dupes:
            for doc1, doc2, sim in dupes[:10]:
                print(f"\n{sim:.1%} ç›¸ä¼¼åº¦:")
                print(f"  1. {doc1}")
                print(f"  2. {doc2}")
        else:
            print("\nâœ“ æ— é‡å¤å†…å®¹")

    elif command == "tree":
        print("ğŸ“‚ docs/ ç»“æ„")
        print("=" * 50)

        for item in sorted(DOCS_DIR.iterdir()):
            if item.is_dir() and not item.name.startswith("."):
                count = len(list(item.rglob("*.md")))
                print(f"ğŸ“ {item.name}/ ({count} ä¸ª md æ–‡ä»¶)")
            elif item.suffix == ".md":
                print(f"ğŸ“„ {item.name}")


if __name__ == "__main__":
    main()
